{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd3f85-d9b4-4602-a0af-c6d5fe8b50d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, text, tags, word2idx, tag2idx, max_len):\n",
    "        self.texts = texts\n",
    "        self.tags = tags\n",
    "        self.word2idx = word2idx\n",
    "        self.tag2idx = tag2idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        words = self.texts[idx]\n",
    "        tags = self.tags[idx]\n",
    "\n",
    "        # Convert words and tags into values\n",
    "        word_ids = [self.word2idx.get(w, self.word2idx['<UNK>']) for w in words]\n",
    "        tag_ids = [self.tag2idx[t] for t in tags]\n",
    "\n",
    "        # Pad sequences\n",
    "        word_ids = word_ids + [self.word2idx['<PAD>']] * (self.max_len - len(word_ids))\n",
    "        tag_ids = tag_ids + [self.tag2idx['O']] * (self.max_len - len(tag_ids))\n",
    "\n",
    "        return torch.tensor(word_ids), torch.tensor(tag_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7de1ff-120e-436c-9852-a8a33d745876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NERLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, embedding_dim=128, hidden_dim=128):\n",
    "        super(NERLSTM).__init__()\n",
    "\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embedding_dim, padding_idx=word2idx['<PAD>'])\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, max_len)\n",
    "        embeds = self.embedding(x)\n",
    "\n",
    "        lstm_out, _  = self.lstm(embeds)\n",
    "\n",
    "        tag_scores = self.fc(lstm_out)\n",
    "\n",
    "        return tag_scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
